{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJCeDh55qLpF",
        "outputId": "14ba5155-dda6-49f8-f9c9-1020790f6018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Personalized Learning Report ===\n",
            "Conscientiousness: 6.49/10\n",
            "Motivation: 6.64/10\n",
            "Understanding: 5.35/10\n",
            "Engagement: 5.89/10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the model and tokenizer from the saved directory\n",
        "model = BertForSequenceClassification.from_pretrained(checkpoint_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint_dir)\n",
        "\n",
        "def calculate_learning_measures(logins, time_spent, page_visits, search_queries, activity_completion, quiz_score, content_reactions_positive, content_reactions_negative, feedback):\n",
        "    input_text = f\"{logins} {time_spent} {page_visits} {search_queries} {activity_completion} {quiz_score} {content_reactions_positive} {content_reactions_negative} {feedback}\"\n",
        "    tokens = tokenizer(input_text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    tokens = {key: value.to('cuda' if torch.cuda.is_available() else 'cpu') for key, value in tokens.items()}\n",
        "    with torch.no_grad():\n",
        "        output = model(**tokens)\n",
        "        scores = torch.sigmoid(output.logits).squeeze(0).cpu().numpy()\n",
        "\n",
        "    return {\n",
        "        'Conscientiousness': round(scores[0] * 10, 2),\n",
        "        'Motivation': round(scores[1] * 10, 2),\n",
        "        'Understanding': round(scores[2] * 10, 2),\n",
        "        'Engagement': round(scores[3] * 10, 2)\n",
        "    }\n",
        "\n",
        "def generate_personalized_learning_report(learning_scores):\n",
        "    \"\"\"\n",
        "    Generates a personalized learning report based on given learning scores.\n",
        "\n",
        "    Args:\n",
        "        learning_scores (dict): A dictionary containing learning measures scores.\n",
        "            Expected keys: 'Conscientiousness', 'Motivation', 'Understanding', 'Engagement'.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted personalized learning report.\n",
        "    \"\"\"\n",
        "    # Extracting scores\n",
        "    conscientiousness = learning_scores.get('Conscientiousness', 0)\n",
        "    motivation = learning_scores.get('Motivation', 0)\n",
        "    understanding = learning_scores.get('Understanding', 0)\n",
        "    engagement = learning_scores.get('Engagement', 0)\n",
        "\n",
        "    # Report Header\n",
        "    report = [\n",
        "        \"=== Personalized Learning Report ===\",\n",
        "        f\"Conscientiousness: {conscientiousness}/10\",\n",
        "        f\"Motivation: {motivation}/10\",\n",
        "        f\"Understanding: {understanding}/10\",\n",
        "        f\"Engagement: {engagement}/10\",\n",
        "        \"\"\n",
        "    ]\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "personalized_report = generate_personalized_learning_report(learning_scores)\n",
        "print(personalized_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhzA9jXgquff",
        "outputId": "e4e87e30-811a-411e-99b9-b94fd94b0d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradientai in /usr/local/lib/python3.10/dist-packages (1.11.0)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from gradientai) (3.1.15)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from gradientai) (1.10.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Created model adapter with id e84d6e4c-e6b4-4ff2-a1cd-2c364f287a0d_model_adapter\n",
            "Welcome to the personalized chatbot! Type 'quit' to exit.\n",
            "\n",
            "Please enter your query or question: How to improve my reading skills\n",
            "\n",
            "Personalized Response:  Improving your reading skills can be a challenging task, but with consistent practice and dedication, you can achieve significant progress. Here are some effective ways to improve your reading skills:\n",
            "\n",
            "1. Set specific goals: Setting specific goals for your reading will help you focus your efforts and track your progress. Identify areas you want to improve, such as comprehension, vocabulary, or speed, and set achievable goals for yourself.\n",
            "2. Practice regularly: Regular practice is essential to improve your reading skills. Allocate time each day to read, whether it's a book, article, or newsletter. Consistency is key to developing muscle memory and improving your reading abilities.\n",
            "3. Diversify your reading material: Expose yourself to different types of texts, such as fiction, non-fiction, articles, and news. This will help you develop a broader vocabulary and improve your comprehension of different writing styles.\n",
            "4. Use active reading strategies: Active reading involves engaging with the material you're reading by asking questions, making connections, and summarizing what you've read. This approach can help you retain information better and improve your comprehension.\n",
            "5. Improve your vocabulary: Expanding your vocabulary can help you understand and interpret text more effectively. Read books, articles, and other materials that challenge you and use flashcards or other tools to learn new words.\n",
            "6. Use technology to your advantage: There are many digital tools and apps that can help you improve your reading skills. For example, you can use e-readers, text-to-speech software, or speed reading apps to enhance your reading experience.\n",
            "7. Join a book club or find a reading buddy: Discussing what you've read with others can help you gain new insights and perspectives. Joining a book club or finding a reading buddy can also provide motivation and accountability.\n",
            "8. Take breaks and practice mindfulness: Reading can be mentally taxing, so it's essential to take breaks and practice mindfulness. Taking short breaks can help you recharge and improve your focus, while mindfulness practices can help you manage stress and anxiety.\n",
            "9. Seek feedback and evaluate your progress: Identify areas where you struggle and seek feedback from others. Use this feedback to evaluate your\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade\n",
        "from gradientai import Gradient\n",
        "import os\n",
        "\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = ''\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = ''\n",
        "\n",
        "# Initialize the Gradient SDK\n",
        "gradient = Gradient()\n",
        "\n",
        "# Get the base model and create a new model adapter\n",
        "base_model = gradient.get_base_model(base_model_slug=\"llama2-7b-chat\")\n",
        "new_model_adapter = base_model.create_model_adapter(name=\"test model 3\")\n",
        "print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "class ContextualChatbot:\n",
        "    def __init__(self, model_adapter, learning_scores):\n",
        "        self.model_adapter = model_adapter\n",
        "        self.learning_scores = learning_scores\n",
        "        self.conversation_history = \"\"\n",
        "\n",
        "    def generate_response(self, user_prompt):\n",
        "        \"\"\"\n",
        "        Generates a response based on user input and existing conversation history.\n",
        "\n",
        "        Args:\n",
        "            user_prompt (str): The input question or prompt provided by the user.\n",
        "\n",
        "        Returns:\n",
        "            str: A contextual response generated by the model adapter.\n",
        "        \"\"\"\n",
        "        # Update the conversation history with the latest user prompt\n",
        "        self.conversation_history += f\"\\nUser: {user_prompt}\\n\"\n",
        "\n",
        "        # Create personalization context\n",
        "        personalization_context = (f\"As an assistant, I understand your learning characteristics as follows:\\n\"\n",
        "                                   f\"Conscientiousness: {self.learning_scores['Conscientiousness']}, \"\n",
        "                                   f\"Motivation: {self.learning_scores['Motivation']}, \"\n",
        "                                   f\"Understanding: {self.learning_scores['Understanding']}, \"\n",
        "                                   f\"Engagement: {self.learning_scores['Engagement']}.\\n\"\n",
        "                                   \"Let's continue our chat.\\n\")\n",
        "\n",
        "        # Create the complete prompt by combining the personalization context and conversation history\n",
        "        complete_prompt = personalization_context + self.conversation_history\n",
        "\n",
        "        # Generate a response using the model adapter\n",
        "        response = new_model_adapter.complete(query=user_prompt, max_generated_token_count=511).generated_output\n",
        "\n",
        "        # Update the conversation history with the assistant's response\n",
        "        self.conversation_history += f\"Assistant: {response}\\n\"\n",
        "\n",
        "        return response\n",
        "\n",
        "# Example learning scores (replace with real data)\n",
        "learning_scores = {\n",
        "    'Conscientiousness': 8.0,\n",
        "    'Motivation': 7.5,\n",
        "    'Understanding': 9.0,\n",
        "    'Engagement': 7.0\n",
        "}\n",
        "\n",
        "# Initialize the chatbot instance\n",
        "chatbot = ContextualChatbot(model_adapter=new_model_adapter, learning_scores=learning_scores)\n",
        "\n",
        "# Continuously chat with the user until they decide to quit\n",
        "print(\"Welcome to the personalized chatbot! Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user_prompt = input(\"\\nPlease enter your query or question: \")\n",
        "\n",
        "    if user_prompt.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "        print(\"Exiting the chat. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = chatbot.generate_response(user_prompt)\n",
        "    print(\"\\nPersonalized Response:\", response)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
